{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEJCAYAAABohnsfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAATw0lEQVR4nO3de5BdVZXH8W/S3dEMCEgFTGJAoZCFOgNBecwMr6gghaKIIyJEICgghVjUiIJKGB4lzgylQXGIUvIIThCYAXEsIb6i8hgEH7xKkTXMqNFIKFRUXgbSSeaPc9pcQnezSfU596b7+6lK0Xfdc7MXSad/d599zz6T1q5diyRJJSZ3uwFJ0sbD0JAkFTM0JEnFDA1JUjFDQ5JUrL/bDTQlIl4A7A6sAFZ3uR1J2lj0ATOAH2bmU+s/OW5Dgyowbul2E5K0kdoHuHX94ngOjRUAV155JdOnT+92L5K0UXjooYeYO3cu1D9D1zeeQ2M1wPTp05k1a1a3e5Gkjc2wp/VdCJckFTM0JEnFDA1JUjFDQ5JUzNCQJBUzNCRJxQwNSVIxQ6NlawZXjcuxJE0M4/nivp40uX+AH59/XCtjvfa0S1oZR9LE4UxDklTM0JAkFTM0JEnFDA1JUjFDQ5JUzNCQJBUzNCRJxQwNSVIxQ0OSVMzQkCQVMzQkScUMDUk9ZXBwcFyONV64YaGkntLf38+nPvWpVsY69dRTWxlnPHGmoa5Z/XR7W7e3OZY0njnTUNf0TRngxqOPbWWsN33x8lbGkcY7ZxqSpGKGhiSpmKEhSSpmaEiSihkakqRihoYk9ahVq9f03Fh+5HaCenpwFVP6B8bNONJ4NNA3mQ9ef1MrYy04dL+i4wyNCWpK/wDzLj+l8XEWHfuZxsfQ2FkzuJrJ/X3jZhyNvQkVGk+vWs2Ugea/UdsaRxprk/v7uGfh9xofZ5eT5jQ+hpoxoUJjykAfR552ZePjfOn8uY2PIUnd0HhoRMQngWmZOS8iZgOXAJsBNwMnZuZgRGwLLAa2BhKYm5mPR8QWwJXA9sBvgXdm5kNN96yJZXDVavpbmBm2NY7UpEZDIyLeABwD3FCXFgPHZebtEXEpcDzwOWAhsDAzr46IM4EzgdOBjwO3ZOabI+Io4DPA4U32rImnf6CPT5xxbePjfOy8dzQ+hsbOmtWrmNzX/Ic42hpnrDQWGhGxJXAe8Algl4h4GTA1M2+vD1kEnBMRlwD7Am/rqN9EFRpvrp8DuAq4KCIGMtMtSyU1anLfADd/7ezGx9n34ObHGEtNXqdxMXAG8If68UxgRcfzK4BZwDTg0cwcXK/+jNfUzz8KbNVgz5KkUTQSGhFxHPDrzFy63lhrOx5PAtYMU6euDx3TaVLHc5KkljV1eupwYEZE3A1sCWxKFQwzOo6ZDjwIPAxsHhF9mbm6PubB+pjf1Mctj4h+4EXA7xvqWZL0HBqZaWTmAZn515k5G/gn4KuZeSywMiL2qg87ClhSr0/cwroF7qOBJfXXN9aPqZ+/xfUMSeqetq/TmAt8ISI2A+4ELqzrJwFXRMR84FfAEXX9TGBRRPwU+GP9eklSlzQeGpm5iOoTUWTmPcAewxyzDJgzTP0R4K2NNihJKuYut5KkYoaGJKmYoSFJKmZoSJKKGRpSDxhc1d4nydscS+PPhNoaXepV/QMDLPjo+1oZ64P/fHEr42h8cqYhSSpmaEiSihkakqRihoYkqZihIUkqZmhIkooZGpKkYoaGJKmYoSFJKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRihoYkqZihIUkqZmhIkooZGpKkYoaGJKmYoSFJKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRihoYkqZihIUkq1t/kbx4R5wLvANYCl2bmgojYH1gATAWuycz59bGzgUuAzYCbgRMzczAitgUWA1sDCczNzMeb7FuSNLzGZhoRsR/wemBnYDfgAxGxC3AZcAjwSmD3iDiofsli4OTM3BGYBBxf1xcCCzNzJ+BHwJlN9SxJGl1joZGZNwGvy8xBqllCP7AF8EBm/qKuLwYOi4iXAVMz8/b65Yvq+gCwL3BtZ72pniVJo2t0TSMzV0XEOcB9wFJgJrCi45AVwKxR6tOAR+uA6axLkrqg8YXwzDwL2ArYBtiRan1jyCRgTd1HSZ26LknqgibXNHaqF7fJzCeBLwNzgBkdh00HHgSWj1B/GNg8Ivrq+oy6LknqgiZnGtsDX4iIF0TEFKrF74uBiIgd6iA4EliSmcuAlRGxV/3ao+r6KuAW4PC6fjSwpMGeJUmjaHIh/EbgBuAu4MfAbZl5NTAPuI5qneN+1i1yzwUuiIj7gU2BC+v6ScAJEXEfsA8wv6meJUmja/Q6jcw8Gzh7vdpSYJdhjr0H2GOY+jKq01qSpC7zinBJUjFDQ5JUzNCQJBUzNCRJxQwNSVIxQ0OSVKwoNCLipcPUXjX27UiSetmo12lExJb1lzdGxByqPaEABqi2BdmpudYkSb3muS7uuwo4oP769x31QdZdyS1JmiBGDY3MPBAgIi7LzPe005IkqVcVbSOSme+pb5S0JetOUZGZdzbVmCSp9xSFRn0jpQ9TbVU+dH+LtVQ72UqSJojSDQuPBnbITO9lIUkTWOl1Gr82MCRJpTONpRFxPvBfwJ+Hiq5pSNLEUhoa8+r/HtZRc01DkiaY0k9Pbdd0I5Kk3lf66akPDlfPzAVj244kqZeVnp76m46vpwD7AUvHvh1JUi8rPT11bOfjiJgJXNpIR5KknrVBW6PXH799+di2IknqdRuypjEJ2I3q6nBJ0gSyIWsaa4FfUW0rIkmaQJ7Xmka9aeFAZv5vo11JknpS6empHaiuBp8JTI6I3wEHZ+bPmmxOktRbShfC/w04PzNfnJmbAx8HLmquLUlSLyoNjZdk5hVDDzLzcmCrZlqSJPWq0tDo77hfOBExjXX31ZAkTRCln576LHB7RFxDFRbvAi5orCtJUk8qnWncSBUWU4BXAS8Frm+qKUlSbyoNjUXARZl5OvBu4AzgsqaakiT1ptLQmJaZFwJk5srM/DQwo7m2JEm96PkshM8cehARL6HaTkSSNIGULoQvAO6OiK9TrW3sj9uISNKEUzTTyMzLqILiLuBHwIGZ+aUmG5Mk9Z7SmQaZeS9w7/P5zSPiLOCd9cMbMvO0iNifauYyFbgmM+fXx84GLgE2A24GTszMwYjYFlgMbA0kMDczH38+fUiSxsYG3U+jRB0ObwR2BWYDr42II6g+dXUI8Epg94g4qH7JYuDkzNyRar3k+Lq+EFiYmTtRzXLObKpnSdLoGgsNYAVwamY+nZmrgJ8BOwIPZOYvMnOQKigOq3fPnZqZt9evXVTXB4B9gWs76w32LEkaRfHpqecrM3869HVEvILqNNVnqcJkyApgFtXuucPVpwGP1gHTWZckdUGTMw0AIuLVwLeoPm31c565Z9UkYE3dR0mdui5J6oJGQyMi9gKWAh+pd8ldzjMvCpwOPDhK/WFg84joq+sz6rokqQuaXAjfBvgKcGRmXl2X76ieih3qIDgSWJKZy4CVdcgAHFXXVwG3AIfX9aOBJU31LEkaXWNrGsCHgBcCCyJiqPZ5YB5wXf3cjaxb5J4LfCEiNgPuBC6s6ycBV0TEfKp7kx/RYM+SpFE0uRB+CnDKCE/vMszx9wB7DFNfBswZ0+YkSRuk8YVwSdL4YWhIkooZGpKkYoaGJKmYoSFJKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRihoYkqZihIUkqZmhIkooZGpKkYoaGJKmYoSFJKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRihoYkqZihIUkqZmhIkooZGpKkYoaGJKmYoSFJKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRi/U0PEBGbAbcBB2fmLyNif2ABMBW4JjPn18fNBi4BNgNuBk7MzMGI2BZYDGwNJDA3Mx9vum9J0rM1OtOIiD2BW4Ed68dTgcuAQ4BXArtHxEH14YuBkzNzR2AScHxdXwgszMydgB8BZzbZsyRpZE2fnjoeeD/wYP14D+CBzPxFZg5SBcVhEfEyYGpm3l4ft6iuDwD7Atd21hvuWZI0gkZPT2XmcQARMVSaCazoOGQFMGuU+jTg0TpgOuuSpC5oeyF8MrC24/EkYM3zqFPXJUld0HZoLAdmdDyeTnXqaqT6w8DmEdFX12ew7lSXJKllbYfGHUBExA51EBwJLMnMZcDKiNirPu6our4KuAU4vK4fDSxpuWdJUq3V0MjMlcA84DrgPuB+1i1yzwUuiIj7gU2BC+v6ScAJEXEfsA8wv82eJUnrNH6dBkBmvrzj66XALsMccw/Vp6vWry8D5jTYniSpkFeES5KKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRihoYkqZihIUkqZmhIkooZGpKkYoaGJKmYoSFJKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRihoYkqZihIUkqZmhIkooZGpKkYoaGJKmYoSFJKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRihoYkqZihIUkqZmhIkooZGpKkYoaGJKmYoSFJKtbf7QZKRMSRwHxgAPh0Zl7U5ZYkaULq+ZlGRLwUOA/YG5gNnBARr+puV5I0MW0MM439ge9k5iMAEXEt8A7g3Od4XR/AQw899IziU0/+sYEWn2n58uWjPv/bx1Y23kNJHyv/+GTXe3jkqd74s3j8iT90vYfHnvhz4z2U9PHwo7/reg+PPfZY4z2U9PG7Rx7veg9PPtL830dnHx0/M/uGO27S2rVrW2loQ0XER4FNMnN+/fg4YI/MPOE5Xrc3cEsLLUrSeLRPZt66fnFjmGlMBjqTbRKwpuB1PwT2AVYAqxvoS5LGoz5gBtXP0GfZGEJjOdUP/yHTgQef60WZ+RTwrJSUJD2n/xvpiY0hNL4NnB0RWwFPAP8AjHpqSpLUjJ7/9FRm/gY4A/gucDfwpcz8QXe7kqSJqecXwiVJvaPnZxqSpN5haEiSihkakqRihoYkqdjG8JHbrumVjRIjYjPgNuDgzPxlF8Y/C3hn/fCGzDyt7R7qPs6l2kJmLXBpZi7oRh91L58EpmXmvC6N/11ga2BVXXpfZt7Rcg9vAc4CNgG+mZmntDl+3cNxwMkdpe2Af8/Mk0d4SVN9vBv4aP1wSWZ+qM3xO/r4CHAs8BRwTWaeN9ZjONMYQa9slBgRe1JdpLhj22PX4+8PvBHYlerP4bURcWgX+tgPeD2wM7Ab8IGIiLb7qHt5A3BMN8aux59E9f2wS2bOrn+1HRjbA58H3kb1d/KaiDiozR4AMvOSoT8DYC7wMHB2mz1ExF8BFwL7AbsA+9T/blpVj3kksDvVv9c9I+LtYz2OoTGyv2yUmJlPAEMbJbbteOD9FFwF35AVwKmZ+XRmrgJ+BmzbdhOZeRPwuswcpHqH3U91sWerImJLqjcTn2h77M426v9+MyLuiYhW31XXDqV6J7u8/r44HGg1uIbxOeBjmdnODn/r9FH9LN2E6qzEANDO7pPPtCvwjcx8NDNXA1+nCvUxZWiMbCbVD8whK4BZbTeRmcdlZtc2XszMn2bm7QAR8Qqq01Q3dqmXVRFxDnAfsBT4TRfauJjqYtPmt8Ud2Yup/v8PBd4AnBgRB7Tcww5AX0R8NSLuBk6ii38m9bvsqZn5n22PnZmPAWcC91Nte/RLqtPJbbsTODAitoyIFwJvpdp2aUwZGiPb0I0Sx6WIeDXwLeDDmflAt/rIzLOArYBtqGZhranPn/86M5e2Oe76MvP7mXl0Zv6pfld9KfCmltvop5qNvxf4O2BPunjKDngf0JU1rojYGXgP8DKqN5urgdbXNOrvy0XA96hmGbcCT4/1OIbGyJZT7fQ4pGijxPEoIvaiemf7kcy8oks97BQRswEy80ngy1Tn0tt0OPDG+p31ucBbI+KClnsgIvau11WGTGLdgnhbHgK+nZm/zcw/A9cDe7TcAwARMYVqPeGr3RgfOBBYmpkP1xulLgLmtN1ERLwIuC4zd87MOVSL4SNuPLih/PTUyNwoEYiIbYCvAIdn5ne62Mr2wDn1fVLWAocAl7XZQGb+5RRQRMwD5mTmP7bZQ20L4NyI+Huq8+fHACe23MPXgCsiYgvgMeAgqu+TbtgZ+J967bEb7gHOj4hNgCeBtzDCtuIN2w74YkTsRrW+8t7615hypjECN0r8iw8BLwQWRMTd9a+2f0CRmTcCNwB3AT8GbsvMq9vuoxdk5td45p/FZZn5/ZZ7uAM4n+oUyH3AMuDyNnvosD3VmYGuyMxvAldR/V3cSxXk/9KFPu4Frqt7+AHVZQL/PdbjuGGhJKmYMw1JUjFDQ5JUzNCQJBUzNCRJxQwNSVIxQ0MaIxExJyJ+8hzHrI2Iac/z910UEV3ZNVVan6EhSSrmFeHSGIuIHYGLgBdRbUVzN9UV9SvrQ86LiN2p3rTNry/WIyLeS7Xx32Tg98DJmXl/2/1Lo3GmIY2944ErMvNvqXaD3Q54c8fzP8/M1wDvptqKY6v6fiHHAPtk5q5UV1tf33Lf0nNypiGNvdOBAyLiNKqbJc0ENu14/vMAmfmTiLiPapfYvakC5raOe0u9uL5/h9QzDA1p7F1F9W/rP6j2iNqWaifaIas7vp5MtUNtH9VtSk8HiIjJVGHTzft2SM/i6Slp7B0InJuZ19SP96QKhSHzACLiNVSzizuAbwBHRMTQdvwnUm1HL/UUZxrS2PsYcH1EPAH8CbiJKhyGbB8Rd1Ft8f6uzHyE6tat/wp8KyLWAI8Cb8/MtV26Fbo0LHe5lSQV8/SUJKmYoSFJKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRi/w//J2Ur9cBB5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train = train[\"label\"]\n",
    "\n",
    "# Drop 'label' column\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "\n",
    "# free some space\n",
    "del train \n",
    "\n",
    "g = sns.countplot(Y_train)\n",
    "\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed=2\n",
    "# Split the train and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some examples\n",
    "g = plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting (accuracy 0.99286)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-54b73dab410d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                               , callbacks=[learning_rate_reduction])\n\u001b[0m",
      "\u001b[0;32m~/Documents/Anaconda/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Anaconda/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Anaconda/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Anaconda/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/Documents/Anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at confusion matrix \n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some error results \n",
    "\n",
    "# Errors are difference between predicted labels and true labels\n",
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = X_val[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "\n",
    "# Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 6 errors \n",
    "most_important_errors = sorted_dela_errors[-6:]\n",
    "\n",
    "# Show the top 6 errors\n",
    "display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
